{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0pChwmIuoKA"
      },
      "outputs": [],
      "source": [
        "!pip install subgrounds\n",
        "!pip install flipside\n",
        "!pip install duckdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkgrtfJnvIu-"
      },
      "outputs": [],
      "source": [
        "from subgrounds.subgrounds import Subgrounds\n",
        "sg = Subgrounds()\n",
        "hop_prtocol_transfers = sg.load_subgraph('https://gateway.thegraph.com/api/[api-key]/subgraphs/id/Cjv3tykF4wnd6m9TRmQV7weiLjizDnhyt6x2tTJB42Cy')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Receive transaction data**"
      ],
      "metadata": {
        "id": "OeXxLkdvvtTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAHoOWlgvPg1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "raw_data = pd.DataFrame()\n",
        "\n",
        "transfers_first_100k = hop_prtocol_transfers.Query.transferSentToL2S(\n",
        "  orderBy=hop_prtocol_transfers.TransferSentToL2.timestamp,\n",
        "  orderDirection='asc',\n",
        "  first=100000\n",
        ")\n",
        "\n",
        "first_100k_result = sg.query_df(transfers_first_100k).squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [raw_data, first_100k_result]\n",
        "raw_data = pd.concat(frames, ignore_index=True)"
      ],
      "metadata": {
        "id": "8ETAXbW3NWL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4tP8KRTkn56O"
      },
      "outputs": [],
      "source": [
        "chunk = 100000\n",
        "while 1:\n",
        "    next_chunk = hop_prtocol_transfers.Query.transferSentToL2S(\n",
        "    orderBy=hop_prtocol_transfers.TransferSentToL2.timestamp,\n",
        "    orderDirection='asc',\n",
        "    skip=chunk,\n",
        "    first=100000)\n",
        "    next_chunk = sg.query_df(next_chunk).squeeze()\n",
        "    if next_chunk.empty:\n",
        "        break\n",
        "    frames = [raw_data, next_chunk]\n",
        "    raw_data = pd.concat(frames, ignore_index=True)\n",
        "    chunk += 100000\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = raw_data[['transferSentToL2S_timestamp',\n",
        "                   'transferSentToL2S_transactionHash', 'transferSentToL2S_from',\n",
        "                   'transferSentToL2S_amount', 'transferSentToL2S_token',\n",
        "                   'transferSentToL2S_destinationChainId']]"
      ],
      "metadata": {
        "id": "iyHfUERL8Mb2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transform raw data**"
      ],
      "metadata": {
        "id": "tNF_qa2YCyb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def obtain_chain_name(chain_id):\n",
        "    if chain_id == 137:\n",
        "        return \"Polygon\"\n",
        "    elif chain_id == 10:\n",
        "        return \"Optimism\"\n",
        "    elif chain_id == 100:\n",
        "        return \"Gnosis\"\n",
        "    elif chain_id == 8453:\n",
        "        return \"Base\"\n",
        "    elif chain_id == 42161:\n",
        "        return \"Arbitrum One\"\n",
        "    elif chain_id == 42170:\n",
        "        return \"Arbitrum Nova\"\n",
        "\n",
        "\n",
        "def obtain_token_decimals(token_name):\n",
        "    if token_name == \"USDC\" or token_name == \"USDT\":\n",
        "        return pow(10, 6)\n",
        "    elif token_name == \"DAI\" or token_name == \"ETH\" or token_name == \"MATIC\":\n",
        "        return pow(10, 18)\n",
        "    elif token_name == \"WBTC\":\n",
        "        return pow(10, 8)\n",
        "\n",
        "\n",
        "def fix_days(row):\n",
        "    row[0] = row[0][0:10]\n",
        "    return row\n",
        "\n",
        "def convert_timestamp(unix_timestamp):\n",
        "    ts = int(unix_timestamp)\n",
        "    timestamp = datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d')\n",
        "    return timestamp\n"
      ],
      "metadata": {
        "id": "Te7qNREjCwXa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "D4KGY1Y7DebV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[\"timestamp\"] = raw_data[\"transferSentToL2S_timestamp\"].apply(convert_timestamp)\n",
        "final_df[\"tx_hash\"] = raw_data[\"transferSentToL2S_transactionHash\"]\n",
        "final_df[\"sender\"] = raw_data[\"transferSentToL2S_from\"]\n",
        "final_df[\"token_name\"] = raw_data[\"transferSentToL2S_token\"]\n",
        "\n",
        "raw_amount = list(map(int, raw_data[\"transferSentToL2S_amount\"].values.tolist()))\n",
        "decimals = list(raw_data[\"transferSentToL2S_token\"].apply(obtain_token_decimals))\n",
        "final_df[\"bridged_amount\"] = list(map(lambda x, y: x / y, raw_amount, decimals))\n",
        "final_df[\"destination_chain\"] = raw_data[\"transferSentToL2S_destinationChainId\"].apply(obtain_chain_name)"
      ],
      "metadata": {
        "id": "q-UvMAK-DPxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# receive token prices from Flipsidecrypto API\n",
        "from flipside import Flipside\n",
        "\n",
        "\n",
        "flipside = Flipside(\"[api-key]\", \"https://api-v2.flipsidecrypto.xyz\")\n",
        "sql = \"\"\"SELECT HOUR::date AS DAYS, AVG(PRICE),\n",
        "CASE WHEN SYMBOL = 'WETH' THEN 'ETH\n",
        "' ELSE SYMBOL END AS\n",
        "TOKEN_NAME\n",
        "FROM ethereum.core.fact_hourly_token_prices\n",
        " WHERE SYMBOL IN ('WETH', 'USDC', 'USDT', 'DAI', 'MATIC', 'WBTC') AND DAYS > '2021-06-16'\n",
        " GROUP BY DAYS, SYMBOL\"\"\"\n",
        "\n",
        "query_result_set = flipside.query(sql)\n",
        "\n",
        "t = list(query_result_set)\n",
        "daily_prices = t[4][1]\n",
        "daily_prices = list(map(fix_days, daily_prices))\n",
        "daily_prices_df = pd.DataFrame(daily_prices, columns=[\"timestamp\", \"price\", \"token_name\", \"t_index\"])\n",
        "daily_prices_df.drop([\"t_index\"], axis=1, inplace=True)\n",
        "daily_prices_df[\"token_name\"] = daily_prices_df[\"token_name\"].replace('\\n', '', regex=True)"
      ],
      "metadata": {
        "id": "aRL77C-IDrJN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.merge(final_df, daily_prices_df, on=['timestamp', 'token_name'], how='inner')\n",
        "final_df[\"bridged_amount_usd\"] = final_df[\"price\"].multiply(final_df[\"bridged_amount\"])"
      ],
      "metadata": {
        "id": "czKRJsy2EBPd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Querying data**"
      ],
      "metadata": {
        "id": "xoy5ctqhE1Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import  duckdb\n"
      ],
      "metadata": {
        "id": "a2Rq_BSOFDfc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Total volume of bridged tokens\n",
        "*   Total number of transactions\n",
        "*   Total number of addresses"
      ],
      "metadata": {
        "id": "c_BBB4nXFTc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "totals = duckdb.sql('SELECT COUNT(distinct( sender)) AS number_of_users, COUNT(DISTINCT (tx_hash)) AS number_of_transactions,'\n",
        "           ' sum(bridged_amount_usd) AS volume_of_bridged_tokens '\n",
        "           'From final_df ').to_df().to_json(orient='records', path_or_buf=\"totals.json\")"
      ],
      "metadata": {
        "id": "Z6SlXZSzE3YW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Weekly volume of bridged tokens based on destination chain\n",
        "*   Weekly number of transactions based on destination chain\n",
        "*   Weekly number of addresses based on destination chain\n",
        "\n"
      ],
      "metadata": {
        "id": "xP5lQCnYGuwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_destination_chain = duckdb.sql('SELECT date_trunc(\\'week\\', timestamp::date) as weeks, destination_chain, COUNT(distinct( sender)) AS number_of_addresses,'\n",
        "            ' COUNT(DISTINCT (tx_hash)) AS number_of_transactions,' ' sum(bridged_amount_usd) AS volume_of_bridged_tokens '\n",
        "           'From final_df'\n",
        "            ' GROUP BY weeks, destination_chain order by weeks asc').to_df().to_json(orient='records', date_unit='s', date_format = 'iso', path_or_buf=\"daily_destination_chain.json\")"
      ],
      "metadata": {
        "id": "Z90o_lPlFP3l"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Weekly volume of bridged tokens based on token name\n",
        "*   Weekly number of transactions based on token name\n",
        "*   Weekly number of addresses based on token name"
      ],
      "metadata": {
        "id": "pUp6R3BKKige"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_token_name = duckdb.sql('SELECT date_trunc(\\'week\\', timestamp::date) as weeks, token_name, COUNT(distinct( sender)) AS number_of_addresses,'\n",
        "            ' COUNT(DISTINCT (tx_hash)) AS number_of_transactions,' ' sum(bridged_amount_usd) AS volume_of_bridged_tokens '\n",
        "           'From final_df'\n",
        "            ' GROUP BY weeks, token_name order by weeks asc').to_df().to_json(orient='records', date_unit='s', date_format = 'iso', path_or_buf=\"daily_token_name.json\")"
      ],
      "metadata": {
        "id": "8FZDszrfKtsV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total volume of bridges based on destination chain"
      ],
      "metadata": {
        "id": "IjL2BsRMLAbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "volume_of_bridges_based_on_destination_chain = duckdb.sql('SELECT  destination_chain, sum(bridged_amount_usd) AS volume_of_bridged_tokens '\n",
        "           'From final_df group by destination_chain').to_df().to_json(orient='records', path_or_buf=\"volume_of_bridges_based_on_destination_chain.json\")"
      ],
      "metadata": {
        "id": "thpSjqlHK6HN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total volume of bridges based on token name"
      ],
      "metadata": {
        "id": "ApyEpceELUmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "volume_of_bridges_based_on_token = duckdb.sql('SELECT  token_name, sum(bridged_amount_usd) AS volume_of_bridged_tokens '\n",
        "           'From final_df '\n",
        "            'group by token_name order by  volume_of_bridged_tokens desc ').to_df().to_json(orient='records', path_or_buf = \"volume_of_bridges_based_on_token.json\")"
      ],
      "metadata": {
        "id": "HCcwkstoLMzd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total number of transactions based on destination chain"
      ],
      "metadata": {
        "id": "YpFh0iXELke1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_transactions_based_on_destination_chain = duckdb.sql('SELECT  destination_chain, count(distinct (tx_hash)) AS number_of_transactions '\n",
        "           'From final_df group by destination_chain').to_df().to_json(orient='records', path_or_buf=\"number_of_transactions_based_on_destination_chain.json\")"
      ],
      "metadata": {
        "id": "WBgZONTjLgT1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total number of transactions based on token name\n"
      ],
      "metadata": {
        "id": "8FZilHROSVeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_transactions_based_on_token_name = duckdb.sql('SELECT  token_name, count(distinct (tx_hash)) AS number_of_transactions '\n",
        "           'From final_df group by token_name').to_df().to_json(orient='records', path_or_buf=\"number_of_transactions_based_on_token_name.json\")"
      ],
      "metadata": {
        "id": "2DvvIJ5ASelm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total number of addresses based on destination chain"
      ],
      "metadata": {
        "id": "ZKN5_bFQSoC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_addresses_based_on_destination_chain = duckdb.sql('SELECT  destination_chain, count(distinct (sender)) AS number_of_addresses '\n",
        "           'From final_df group by destination_chain').to_df().to_json(orient='records', path_or_buf=\"number_of_addresses_based_on_destination_chain.json\")"
      ],
      "metadata": {
        "id": "utfEEsnbSnF1"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total number of addresses based on token name"
      ],
      "metadata": {
        "id": "z8ThR0SlSxIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_addresses_based_on_token_name = duckdb.sql('SELECT  token_name, count(distinct (sender)) AS number_of_addresses '\n",
        "           'From final_df group by token_name').to_df().to_json(orient='records', path_or_buf=\"number_of_addresses_based_on_token_name.json\")"
      ],
      "metadata": {
        "id": "YxrR20vZS4e9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Growth of volume of bridges"
      ],
      "metadata": {
        "id": "PO8bX2sRTEWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "growth_of_volume_of_bridges = duckdb.sql('SELECT  timestamp ::date as days, sum(bridged_amount_usd) AS volume_of_bridged_tokens,'\n",
        "                                         ' sum(volume_of_bridged_tokens) OVER (ORDER BY days)  as growth_of_volume_of_bridged_tokens '\n",
        "           'From final_df group by days '\n",
        "            'order by days asc ').to_df().to_json(orient='records', date_unit='s', date_format = 'iso' ,path_or_buf=\"growth_of_volume_of_bridged_tokens.json\")"
      ],
      "metadata": {
        "id": "0j65vR6OTDD1"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Growth of number of transactions\n",
        "\n"
      ],
      "metadata": {
        "id": "ug4F-y7cTOLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "growth_of_number_of_transactions = duckdb.sql('SELECT  timestamp ::date as days, count(distinct (tx_hash))AS number_of_transactions,'\n",
        "                                         ' sum(number_of_transactions) OVER (ORDER BY days)  as growth_of_number_of_transactions '\n",
        "           'From final_df group by days '\n",
        "            'order by days asc ').to_df().to_json(orient='records', date_unit='s', date_format = 'iso' ,path_or_buf=\"growth_of_number_of_transactions.json\")"
      ],
      "metadata": {
        "id": "t41Co0OvTSYt"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Growth of number of addresses\n"
      ],
      "metadata": {
        "id": "8zzlNPccTfF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_activity = duckdb.sql('SELECT  min(timestamp) ::date as days, sender '\n",
        "           'From final_df group by sender '\n",
        "            'order by days asc ')\n",
        "#%%\n",
        "growth_of_number_of_addresses = duckdb.sql('SELECT  days, count(distinct (sender)) number_of_addresses ,  sum(number_of_addresses) OVER (ORDER BY days)  as growth_of_number_addresses '\n",
        "           'From first_activity group by days').to_df().to_json(orient='records', date_unit='s', date_format = 'iso' ,path_or_buf=\"growth_of_number_of_addresses.json\")"
      ],
      "metadata": {
        "id": "P2YDcFGkTiJE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 addresses based on the volume of bridges"
      ],
      "metadata": {
        "id": "VT4H01ztWR5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Top_addresses_based_on_the_volume_of_bridges = duckdb.sql('SELECT  sender, sum(bridged_amount) as volume '\n",
        "           'From final_df group by sender order by volume desc limit 10').to_df().to_json(orient='records', path_or_buf=\"Top_addresses_based_on_the_volume_of_bridges.json\")"
      ],
      "metadata": {
        "id": "Mo9L56UOWRkx"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 addresses based on the number of transactions"
      ],
      "metadata": {
        "id": "Td0sAfd7XMB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Top_addresses_based_on_the_number_of_transactions = duckdb.sql('SELECT  sender, count(distinct(tx_hash)) as tx_number '\n",
        "           'From final_df group by sender order by tx_number desc limit 10').to_df().to_json(orient='records', path_or_buf=\"Top_addresses_based_on_the_number_of_transactions.json\")"
      ],
      "metadata": {
        "id": "2_h9tllQXPhA"
      },
      "execution_count": 54,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}